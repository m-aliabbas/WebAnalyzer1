originalContent,correctedSentence,changes,temp_lower
"Back to Top CS229 Gaussian Discriminant Analysis Generative Learning Algorithms Weve mainly looked at learning algorithms that model Pyx, the conditional distribution of y given x.","Back to Top CS229 Gaussian Discriminant Analysis Generative Learning Algorithms We've mainly looked at learning algorithms that model Pyx, the conditional distribution of y given x.","Back to Top CS229 Gaussian Discriminant Analysis Generative Learning Algorithms <b> We've </b> mainly looked at learning algorithms that model Pyx, the conditional distribution of y given x.","back to top cs229 gaussian discriminant analysis generative learning algorithms <b> we've </b> mainly looked at learning algorithms that model pyx, the conditional distribution of y given x."
"For instance, logistic regression modeled Pyx as hxgTx where g is sigmoid function.","For instance, logistic regression modelled Pyx as hxgTx where g is sigmoid function.","For instance, logistic regression <b> modelled </b> Pyx as hxgTx where g is sigmoid function.","for instance, logistic regression <b> modelled </b> pyx as hxgtx where g is sigmoid function."
"In this section, well talk about a different type algorithm.","In this section, we'll talk about a different type of algorithm.","In this section, <b> we'll </b> talk about a different type <b> of </b> algorithm.","in this section, <b> we'll </b> talk about a different type <b> of </b> algorithm."
Lets use binary classification problem motivation behind our discussion.,Let's use binary classification problem motivation behind our discussion.,<b> Let's </b> use binary classification problem motivation behind our discussion.,<b> let's </b> use binary classification problem motivation behind our discussion.
Consider in which we want learn distinguish between malignant y1 and benign y0 tumors.,Consider in which we want to learn to distinguish between malignant y1 and benign y0 tumours.,Consider in which we want <b> to </b> learn <b> to </b> distinguish between malignant y1 and benign y0 <b> tumours. </b>,consider in which we want <b> to </b> learn <b> to </b> distinguish between malignant y1 and benign y0 <b> tumours. </b>
"Given training set, an algorithm like , or initially starts with randomly initialized parameters.","Given a training set, an algorithm like , or initially starts with randomly initialised parameters.","Given <b> a </b> training set, an algorithm like , or initially starts with randomly <b> initialised </b> parameters.","given <b> a </b> training set, an algorithm like , or initially starts with randomly <b> initialised </b> parameters."
"Over course learning, performs gradient descent straight line hyperplane decision boundary evolves until you obtain separates positivenegative examples case, Then, classify new sample either benign, it checks on side falls in, makes its prediction accordingly.","Over the course of learning, it performs gradient descent on a straight line hyperplane decision boundary, which evolves until it separates positive and negative examples. Then, it classifies a new sample as either benign or malignant, depending on which side it falls in, and makes its prediction accordingly.","Over <b> the </b> course <b> of </b> learning, <b> it </b> performs gradient descent <b> on a </b> straight line hyperplane decision <b> boundary, which </b> evolves until <b> it </b> separates <b> positive and negative examples. </b> Then, <b> it classifies a </b> new sample <b> as </b> either <b> benign or malignant, depending on which side </b> it falls in, <b> and </b> makes its prediction accordingly.","over <b> the </b> course <b> of </b> learning, <b> it </b> performs gradient descent <b> on a </b> straight line hyperplane decision <b> boundary, which </b> evolves until <b> it </b> separates <b> positive and negative examples. </b> then, <b> it classifies a </b> new sample <b> as </b> either <b> benign or malignant, depending on which side </b> it falls in, <b> and </b> makes its prediction accordingly."
Theres class arent trying maximize likelihood looking both classes searching for separation boundary.,"There's a class that aren't trying to maximise likelihood, looking at both classes and searching for a separation boundary.","<b> There's a </b> class <b> that aren't </b> trying <b> to maximise likelihood, </b> looking <b> at </b> both classes <b> and </b> searching for <b> a </b> separation boundary.","<b> there's a </b> class <b> that aren't </b> trying <b> to maximise likelihood, </b> looking <b> at </b> both classes <b> and </b> searching for <b> a </b> separation boundary."
"Instead, these look one time.","Instead, these look at one time.","Instead, these look <b> at </b> one time.","instead, these look <b> at </b> one time."
"First, tumors, can features what tumors like.","First, tumours can have features that are like other tumours.","First, <b> tumours </b> can <b> have </b> features <b> that are like other tumours. </b>","first, <b> tumours </b> can <b> have </b> features <b> that are like other tumours. </b>"
"build separate Finally, tumor, match against tumor model, see whether looks more had seen set.","Build separate models for each tumour type. Finally, match the tumour against the tumour model, and see whether it looks more like the tumours in the training set.","<b> Build </b> separate <b> models for each tumour type. </b> Finally, match <b> the tumour </b> against <b> the tumour </b> model, <b> and </b> see whether <b> it </b> looks more <b> like the tumours in the training </b> set.","<b> build </b> separate <b> models for each tumour type. </b> finally, match <b> the tumour </b> against <b> the tumour </b> model, <b> and </b> see whether <b> it </b> looks more <b> like the tumours in the training </b> set."
try directly such mapping from input space X labels are called discriminative algorithms.,"Try to directly map from the input space X to the labels, which are called discriminative algorithms.","<b> Try to </b> directly <b> map </b> from <b> the </b> input space X <b> to the labels, which </b> are called discriminative algorithms.","<b> try to </b> directly <b> map </b> from <b> the </b> input space x <b> to the labels, which </b> are called discriminative algorithms."
instead Pxy Py.,"Instead, Pxy = Py.","<b> Instead, </b> Pxy <b> = </b> Py.","<b> instead, </b> pxy <b> = </b> py."
"These generative if indicates example 0 1, then Pxy0 models features, while Pxy1 features.","These generative models indicate that, for example, Pxy0 models the features of class 0, while Pxy1 models the features of class 1.","These generative <b> models indicate that, for example, </b> Pxy0 models <b> the features of class 0, </b> while Pxy1 <b> models the features of class 1. </b>","these generative <b> models indicate that, for example, </b> pxy0 models <b> the features of class 0, </b> while pxy1 <b> models the features of class 1. </b>"
The also learns prior Py independent probability y.,"The model also learns the prior probability Py, which is independent of y.","The <b> model </b> also learns <b> the </b> prior <b> probability Py, which is </b> independent <b> of </b> y.","the <b> model </b> also learns <b> the </b> prior <b> probability py, which is </b> independent <b> of </b> y."
"To illustrate concept using practical when patient walks into hospital, before doctors even them, odds their versus referred prior.","To illustrate this concept, consider a practical example: when a patient walks into a hospital, before the doctors even see them, the odds of their having a particular disease versus not having it are referred to as the prior probability.","To illustrate <b> this concept, consider a </b> practical <b> example: </b> when <b> a </b> patient walks into <b> a </b> hospital, before <b> the </b> doctors even <b> see </b> them, <b> the </b> odds <b> of </b> their <b> having a particular disease </b> versus <b> not having it are </b> referred <b> to as the prior probability. </b>","to illustrate <b> this concept, consider a </b> practical <b> example: </b> when <b> a </b> patient walks into <b> a </b> hospital, before <b> the </b> doctors even <b> see </b> them, <b> the </b> odds <b> of </b> their <b> having a particular disease </b> versus <b> not having it are </b> referred <b> to as the prior probability. </b>"
"Thus, builds each isolation.","Thus, the model builds each in isolation.","Thus, <b> the model </b> builds each <b> in </b> isolation.","thus, <b> the model </b> builds each <b> in </b> isolation."
"At test time, evaluates models, identifies matches most closely returns prediction.","At test time, the model evaluates the models, identifies which one matches most closely, and returns the prediction.","At test time, <b> the model </b> evaluates <b> the </b> models, identifies <b> which one </b> matches most <b> closely, and </b> returns <b> the </b> prediction.","at test time, <b> the model </b> evaluates <b> the </b> models, identifies <b> which one </b> matches most <b> closely, and </b> returns <b> the </b> prediction."
"After modeling priors Pxy, Bayes rule derive posterior x PyxPxyPyPx","After modelling the priors Pxy, we can derive the posterior probability x using Bayes' rule: Pyx = PxyPyPx","After <b> modelling the </b> priors Pxy, <b> we can </b> derive <b> the </b> posterior <b> probability </b> x <b> using Bayes' rule: Pyx = PxyPyPx </b>","after <b> modelling the </b> priors pxy, <b> we can </b> derive <b> the </b> posterior <b> probability </b> x <b> using bayes' rule: pyx = pxypypx </b>"
"Here, denominator by PxPxy1Py1Pxy0Py0, function quantities","Here, the denominator is given by Px = Pxy1Py1 + Pxy0Py0, which is a function of the quantities","Here, <b> the </b> denominator <b> is given </b> by <b> Px = Pxy1Py1 + Pxy0Py0, which is a </b> function <b> of the </b> quantities","here, <b> the </b> denominator <b> is given </b> by <b> px = pxy1py1 + pxy0py0, which is a </b> function <b> of the </b> quantities"
"Note learned part process calculating order make prediction, dont actually need calculate value Px since constant, doesnt appear there.","Note that the learned part of the process is calculating the order to make a prediction, but we don't actually need to calculate the value of Px since it is a constant and doesn't appear in the final prediction.","Note <b> that the </b> learned part <b> of the </b> process <b> is </b> calculating <b> the </b> order <b> to </b> make <b> a </b> prediction, <b> but we don't </b> actually need <b> to </b> calculate <b> the </b> value <b> of </b> Px since <b> it is a constant and doesn't </b> appear <b> in the final prediction. </b>","note <b> that the </b> learned part <b> of the </b> process <b> is </b> calculating <b> the </b> order <b> to </b> make <b> a </b> prediction, <b> but we don't </b> actually need <b> to </b> calculate <b> the </b> value <b> of </b> px since <b> it is a constant and doesn't </b> appear <b> in the final prediction. </b>"
"When making predictions algorithms, thus ignore computing save computation.","When making predictions, algorithms thus ignore computing Px to save computation.","When making <b> predictions, algorithms </b> thus ignore computing <b> Px to </b> save computation.","when making <b> predictions, algorithms </b> thus ignore computing <b> px to </b> save computation."
"However, end goal value, would compute be able normalize numerator.","However, the end goal is to compute the value of Px, which would allow us to normalise the numerator.","However, <b> the </b> end goal <b> is to compute the value of Px, which </b> would <b> allow us to normalise the </b> numerator.","however, <b> the </b> end goal <b> is to compute the value of px, which </b> would <b> allow us to normalise the </b> numerator."
PyxPxyPyPxPxyPy above equation represents underlying framework .,The equation Pyx = PxyPyPx represents the underlying framework.,<b> The </b> equation <b> Pyx = PxyPyPx </b> represents <b> the </b> underlying <b> framework. </b>,<b> the </b> equation <b> pyx = pxypypx </b> represents <b> the </b> underlying <b> framework. </b>
"Key takeaways Discriminative i.e., output input.","Key takeaways: discriminative models, i.e., output is a function of input.","Key <b> takeaways: discriminative models, </b> i.e., output <b> is a function of </b> input.","key <b> takeaways: discriminative models, </b> i.e., output <b> is a function of </b> input."
"other words, hx0,1 directly.","In other words, hx is 0 or 1 directly.","<b> In </b> other words, <b> hx is 0 or 1 </b> directly.","<b> in </b> other words, <b> hx is 0 or 1 </b> directly."
"class, tumoridentification setting, may case them first discriminant analysis GDA, used continuousvalued say, classification.","In the case of tumour identification, we may use discriminant analysis (GDA) for continuous-valued classification.","<b> In the case of tumour identification, we </b> may <b> use </b> discriminant analysis <b> (GDA) for continuous-valued </b> classification.","<b> in the case of tumour identification, we </b> may <b> use </b> discriminant analysis <b> (gda) for continuous-valued </b> classification."
assume distributed according multivariate normal distribution.,We assume that the data is distributed according to a multivariate normal distribution.,<b> We </b> assume <b> that the data is </b> distributed according <b> to a </b> multivariate normal distribution.,<b> we </b> assume <b> that the data is </b> distributed according <b> to a </b> multivariate normal distribution.
briefly properties distributions moving GDA itself.,We will briefly discuss the properties of the distributions and then move on to GDA itself.,<b> We will </b> briefly <b> discuss the </b> properties <b> of the </b> distributions <b> and then move on to </b> GDA itself.,<b> we will </b> briefly <b> discuss the </b> properties <b> of the </b> distributions <b> and then move on to </b> gda itself.
"Multivariate Distribution generalization 1dimensional random variable ndimensional simply, nrandom variable.",A multivariate distribution is a generalisation of a 1-dimensional random variable to an n-dimensional random variable.,<b> A multivariate distribution is a generalisation of a 1-dimensional </b> random variable <b> to an n-dimensional random </b> variable.,<b> a multivariate distribution is a generalisation of a 1-dimensional </b> random variable <b> to an n-dimensional random </b> variable.
"rather than univariate variable, seeks multiple variables.","Rather than a univariate variable, it seeks multiple variables.","<b> Rather </b> than <b> a </b> univariate variable, <b> it </b> seeks multiple variables.","<b> rather </b> than <b> a </b> univariate variable, <b> it </b> seeks multiple variables."
"Assume Gaussian, i.e, XRn, parameterized mean vector Rn covariance matrix Rnn, symmetric positive semidefinite.","We assume that the data is Gaussian, i.e., X ~ Rn, parameterised by a mean vector in Rn and a covariance matrix in Rnn, which is symmetric and positive semidefinite.","<b> We assume that the data is </b> Gaussian, <b> i.e., X ~ Rn, parameterised by a </b> mean vector <b> in </b> Rn <b> and a </b> covariance matrix <b> in </b> Rnn, <b> which is </b> symmetric <b> and </b> positive semidefinite.","<b> we assume that the data is </b> gaussian, <b> i.e., x ~ rn, parameterised by a </b> mean vector <b> in </b> rn <b> and a </b> covariance matrix <b> in </b> rnn, <b> which is </b> symmetric <b> and </b> positive semidefinite."
"Formally, written as, XN, density PDF PX,12n212exp12XT1X denotes determinant expected ExxPx,dx vectorvalued defined CovX EXET.","Formally, this can be written as X ~ N(μ, Σ), where the density PDF is given by PX(x) = (1/√(2π)^n) * exp(-1/2 * (x-μ)^T * Σ^(-1) * (x-μ)), where μ is the mean vector, Σ is the covariance matrix, and E[x] is the expected value of x.","Formally, <b> this can be </b> written <b> as X ~ N(μ, Σ), where the </b> density PDF <b> is given by PX(x) = (1/√(2π)^n) * exp(-1/2 * (x-μ)^T * Σ^(-1) * (x-μ)), where μ is the mean vector, Σ is the covariance matrix, and E[x] is the </b> expected <b> value of x. </b>","formally, <b> this can be </b> written <b> as x ~ n(μ, σ), where the </b> density pdf <b> is given by px(x) = (1/√(2π)^n) * exp(-1/2 * (x-μ)^t * σ^(-1) * (x-μ)), where μ is the mean vector, σ is the covariance matrix, and e[x] is the </b> expected <b> value of x. </b>"
Covariance generalizes notion variance realvalued setting.,Covariance generalises the notion of variance in the real-valued setting.,Covariance <b> generalises the </b> notion <b> of </b> variance <b> in the real-valued </b> setting.,covariance <b> generalises the </b> notion <b> of </b> variance <b> in the real-valued </b> setting.
EEET.,E[E^T] = E[E]E^T.,<b> E[E^T] = E[E]E^T. </b>,<b> e[e^t] = e[e]e^t. </b>
Since CovX.,"Since Cov(X) = E[(X-E[X])(X-E[X])^T],","Since <b> Cov(X) = E[(X-E[X])(X-E[X])^T], </b>","since <b> cov(x) = e[(x-e[x])(x-e[x])^t], </b>"
explore some visualize Recall familiar,Let's explore some visualisations. Recall the familiar,<b> Let's </b> explore some <b> visualisations. </b> Recall <b> the </b> familiar,<b> let's </b> explore some <b> visualisations. </b> recall <b> the </b> familiar
"Similarly, multivariable represented same bellshaped curve two parameters control PDF, but ndimensions.","Similarly, a multivariate distribution can be represented by the same bell-shaped curve, but with two parameters controlling the PDF in n dimensions.","Similarly, <b> a multivariate distribution can be </b> represented <b> by the </b> same <b> bell-shaped curve, but with </b> two parameters <b> controlling the PDF in n dimensions. </b>","similarly, <b> a multivariate distribution can be </b> represented <b> by the </b> same <b> bell-shaped curve, but with </b> two parameters <b> controlling the pdf in n dimensions. </b>"
"e.g., 2dimensional over 2 variables, 2dimensional, size 22.","For example, a 2-dimensional distribution over 2 variables has a size of 2x2.","<b> For example, a 2-dimensional distribution </b> over 2 <b> variables has a </b> size <b> of 2x2. </b>","<b> for example, a 2-dimensional distribution </b> over 2 <b> variables has a </b> size <b> of 2x2. </b>"
below figure shows zero 21 zerovector I 22 identity matrix.,"The figure below shows a zero-mean vector, a 2x1 zero vector, and a 2x2 identity matrix.","<b> The figure </b> below shows <b> a zero-mean vector, a 2x1 </b> zero <b> vector, and a 2x2 </b> identity matrix.","<b> the figure </b> below shows <b> a zero-mean vector, a 2x1 </b> zero <b> vector, and a 2x2 </b> identity matrix."
A standard 0.6I.,A standard deviation of 0.6I.,A standard <b> deviation of </b> 0.6I.,a standard <b> deviation of </b> 0.6i.
"essentially taken multiplied number has shrunk variance, reduced variability 2I.","Essentially, the number has been multiplied by 0.6, which has shrunk the variance and reduced the variability. 2I.","<b> Essentially, the </b> number has <b> been multiplied by 0.6, which has </b> shrunk <b> the variance and </b> reduced <b> the variability. </b> 2I.","<b> essentially, the </b> number has <b> been multiplied by 0.6, which has </b> shrunk <b> the variance and </b> reduced <b> the variability. </b> 2i."
"From images, becomes larger, widershorter, smaller, compressedtaller.","From the images, we can see that as the covariance matrix becomes larger, the distribution becomes wider and shorter, and as it becomes smaller, the distribution becomes compressed and taller.","From <b> the </b> images, <b> we can see that as the covariance matrix </b> becomes larger, <b> the distribution becomes wider and shorter, and as it becomes </b> smaller, <b> the distribution becomes compressed and taller. </b>","from <b> the </b> images, <b> we can see that as the covariance matrix </b> becomes larger, <b> the distribution becomes wider and shorter, and as it becomes </b> smaller, <b> the distribution becomes compressed and taller. </b>"
"This because always integrates area under so scales spread vs. height figures show Gaussians corresponding matrices figures, increase offdiagonal entries compressed towards 45 x1x2.","This is because the area under the curve always integrates to 1, so as the spread increases, the height decreases, and vice versa. The figures show Gaussians corresponding to the matrices, and as the off-diagonal entries increase, the distribution becomes compressed towards the 45° line between x1 and x2.","This <b> is </b> because <b> the area under the curve </b> always integrates <b> to 1, </b> so <b> as the </b> spread <b> increases, the </b> height <b> decreases, and vice versa. The </b> figures show Gaussians corresponding <b> to the matrices, and as the off-diagonal </b> entries <b> increase, the distribution becomes </b> compressed towards <b> the 45° line between x1 and x2. </b>","this <b> is </b> because <b> the area under the curve </b> always integrates <b> to 1, </b> so <b> as the </b> spread <b> increases, the </b> height <b> decreases, and vice versa. the </b> figures show gaussians corresponding <b> to the matrices, and as the off-diagonal </b> entries <b> increase, the distribution becomes </b> compressed towards <b> the 45° line between x1 and x2. </b>"
"Geometrically speaking, implies variables positively correlated.","Geometrically speaking, this implies that the variables are positively correlated.","Geometrically speaking, <b> this </b> implies <b> that the </b> variables <b> are </b> positively correlated.","geometrically speaking, <b> this </b> implies <b> that the </b> variables <b> are </b> positively correlated."
"We clearly contours three densities 3D bumps saw above, should perfectly round circles, aspect ratio image probably little bit fatter places being","We can clearly see the contours of the three densities, which are 3D bumps. The aspect ratio of the image is probably a little bit fatter in some places, but the contours should be perfectly round circles.","We <b> can </b> clearly <b> see the </b> contours <b> of the </b> three <b> densities, which are </b> 3D <b> bumps. The </b> aspect ratio <b> of the </b> image <b> is </b> probably <b> a </b> little bit fatter <b> in some places, but the contours should be perfectly round circles. </b>","we <b> can </b> clearly <b> see the </b> contours <b> of the </b> three <b> densities, which are </b> 3d <b> bumps. the </b> aspect ratio <b> of the </b> image <b> is </b> probably <b> a </b> little bit fatter <b> in some places, but the contours should be perfectly round circles. </b>"
"Heres another set along decreasing elements matrix, now again, opposite direction, 135 line.","Here's another set of images, this time with decreasing elements of the matrix, and again, in the opposite direction, along the 135° line.","<b> Here's </b> another set <b> of images, this time with </b> decreasing elements <b> of the </b> matrix, <b> and </b> again, <b> in the </b> opposite direction, <b> along the 135° </b> line.","<b> here's </b> another set <b> of images, this time with </b> decreasing elements <b> of the </b> matrix, <b> and </b> again, <b> in the </b> opposite direction, <b> along the 135° </b> line."
"Again, geometrically, endow negative correlation.","Again, geometrically, this endows the variables with a negative correlation.","Again, geometrically, <b> this endows the variables with a </b> negative correlation.","again, geometrically, <b> this endows the variables with a </b> negative correlation."
"vary parameters, tend form ellipses.","As we vary the parameters, the distribution tends to form ellipses.","<b> As we </b> vary <b> the </b> parameters, <b> the distribution tends to </b> form ellipses.","<b> as we </b> vary <b> the </b> parameters, <b> the distribution tends to </b> form ellipses."
By varying shift center around.,By varying the shift of the center around.,By varying <b> the </b> shift <b> of the </b> center around.,by varying <b> the </b> shift <b> of the </b> center around.
"Another values I, visualization PDFs follows carry out eigenvectors points principal axes ellipse contours.",Another way to visualise the PDFs is to carry out the eigenvectors and points of the principal axes of the ellipse contours.,Another <b> way to visualise the </b> PDFs <b> is to </b> carry out <b> the </b> eigenvectors <b> and </b> points <b> of the </b> principal axes <b> of the </b> ellipse contours.,another <b> way to visualise the </b> pdfs <b> is to </b> carry out <b> the </b> eigenvectors <b> and </b> points <b> of the </b> principal axes <b> of the </b> ellipse contours.
"takeaway As density, change spreadheight respectively.","The takeaway is that as the density changes, the spread and height change respectively.","<b> The </b> takeaway <b> is that as the density changes, the spread and height </b> change respectively.","<b> the </b> takeaway <b> is that as the density changes, the spread and height </b> change respectively."
"Model have consider task discussion, expressed equations Pxy1, Gaussians.","The model we have been considering for this task is expressed in terms of equations for Pxy1, which are Gaussians.","<b> The model we </b> have <b> been considering for this </b> task <b> is </b> expressed <b> in terms of </b> equations <b> for </b> Pxy1, <b> which are </b> Gaussians.","<b> the model we </b> have <b> been considering for this </b> task <b> is </b> expressed <b> in terms of </b> equations <b> for </b> pxy1, <b> which are </b> gaussians."
"On hand, Bernoulli takes 0,1.","On the other hand, the Bernoulli distribution takes values 0 and 1.","On <b> the other </b> hand, <b> the </b> Bernoulli <b> distribution </b> takes <b> values 0 and 1. </b>","on <b> the other </b> hand, <b> the </b> bernoulli <b> distribution </b> takes <b> values 0 and 1. </b>"
"by, xy0N0,xy1N1,yBernoulli 0, classes, vectors 1.","By the way, xy0 ~ N0, xy1 ~ N1, and y ~ Bernoulli(0, 1), where the classes are represented by vectors of length 1.","<b> By the way, xy0 ~ N0, xy1 ~ N1, and y ~ Bernoulli(0, 1), where the classes are represented by </b> vectors <b> of length </b> 1.","<b> by the way, xy0 ~ n0, xy1 ~ n1, and y ~ bernoulli(0, 1), where the classes are represented by </b> vectors <b> of length </b> 1."
Put were assuming representing means.,"Put simply, we were assuming that the means are represented by","Put <b> simply, we </b> were assuming <b> that the means are represented by </b>","put <b> simply, we </b> were assuming <b> that the means are represented by </b>"
You not commonly seen.,You may not have commonly seen this.,You <b> may </b> not <b> have </b> commonly <b> seen this. </b>,you <b> may </b> not <b> have </b> commonly <b> seen this. </b>
More section below.,More on this in the section below.,More <b> on this in the </b> section below.,more <b> on this in the </b> section below.
"fit your data, will define data.","To fit your data, we will define the data.","<b> To </b> fit your data, <b> we </b> will define <b> the </b> data.","<b> to </b> fit your data, <b> we </b> will define <b> the </b> data."
"R, 0Rn, 1Rn, Rnn.","R, 0 in Rn, 1 in Rn, and Rnn.","R, <b> 0 in Rn, 1 in Rn, and </b> Rnn.","r, <b> 0 in rn, 1 in rn, and </b> rnn."
"Writing distributions, Pyy11yPxy012n212exp12x0T1x0Pxy112n212exp12x1T1x1","Writing the distributions, Py(y=1) = Pxy0 ~ N(0, 1), Py(y=1) = Pxy1 ~ N(1, 1)","Writing <b> the </b> distributions, <b> Py(y=1) = Pxy0 ~ N(0, 1), Py(y=1) = Pxy1 ~ N(1, 1) </b>","writing <b> the </b> distributions, <b> py(y=1) = pxy0 ~ n(0, 1), py(y=1) = pxy1 ~ n(1, 1) </b>"
"exponential notation similar earlier Plugging Pxy0,Pxy1,Py0 Py1 formula easily ascertain particular example.","Using exponential notation similar to earlier, plugging in Pxy0, Pxy1, Py0, and Py1 into the formula, we can easily ascertain the particular example.","<b> Using </b> exponential notation similar <b> to earlier, plugging in Pxy0, Pxy1, Py0, and </b> Py1 <b> into the formula, we can </b> easily ascertain <b> the </b> particular example.","<b> using </b> exponential notation similar <b> to earlier, plugging in pxy0, pxy1, py0, and </b> py1 <b> into the formula, we can </b> easily ascertain <b> the </b> particular example."
"Suppose xi,yimi1.","Suppose we have xi and yi, for i = 1 to m.","Suppose <b> we have xi and yi, for i = 1 to m. </b>","suppose <b> we have xi and yi, for i = 1 to m. </b>"
"aforementioned going joint L, L,0,1,mi1Pxi,yi,0,1,mi1Pxiyi0,1,Pyi","The aforementioned joint likelihood L is given by L = ∏[P(xi, yi) for i = 1 to m] = ∏[P(xi|yi)P(yi) for i = 1 to m]","<b> The </b> aforementioned joint <b> likelihood L is given by L = ∏[P(xi, yi) for i = 1 to m] = ∏[P(xi|yi)P(yi) for i = 1 to m] </b>","<b> the </b> aforementioned joint <b> likelihood l is given by l = ∏[p(xi, yi) for i = 1 to m] = ∏[p(xi|yi)p(yi) for i = 1 to m] </b>"
"big difference cost functions compared choose ,0,1,, Px,y,0,1,.","There is a big difference between the cost functions. We choose to maximise the likelihood of the data, which is given by L = ∏[P(xi, yi) for i = 1 to m].","<b> There is a </b> big difference <b> between the </b> cost <b> functions. We </b> choose <b> to maximise the likelihood of the data, which is given by L = ∏[P(xi, yi) for i = 1 to m]. </b>","<b> there is a </b> big difference <b> between the </b> cost <b> functions. we </b> choose <b> to maximise the likelihood of the data, which is given by l = ∏[p(xi, yi) for i = 1 to m]. </b>"
"linear regression, generalized Pyx.","In linear regression, we generalise Pyx.","<b> In </b> linear regression, <b> we generalise </b> Pyx.","<b> in </b> linear regression, <b> we generalise </b> pyx."
loglikelihood data simply log L.,The log-likelihood of the data is simply log L.,<b> The log-likelihood of the </b> data <b> is </b> simply log L.,<b> the log-likelihood of the </b> data <b> is </b> simply log l.
",0,1,logmi1Pxi,yi,0,1,logmi1Pxiyi0,1,Pyi","The log-likelihood is given by log L = ∑[log P(xi, yi) for i = 1 to m] = ∑[log P(xi|yi)P(yi) for i = 1 to m]","<b> The log-likelihood is given by log L = ∑[log P(xi, yi) for i = 1 to m] = ∑[log P(xi|yi)P(yi) for i = 1 to m] </b>","<b> the log-likelihood is given by log l = ∑[log p(xi, yi) for i = 1 to m] = ∑[log p(xi|yi)p(yi) for i = 1 to m] </b>"
"respect take derivative equal solve expression yields maximum estimate be, mi1yim","Taking the derivative with respect to the parameters and setting it equal to zero, we can solve for the expression that yields the maximum likelihood estimate, which is given by μ = (1/m) * ∑[yi * xi for i = 1 to m]","<b> Taking the derivative with </b> respect <b> to the parameters and setting it </b> equal <b> to zero, we can </b> solve <b> for the </b> expression <b> that </b> yields <b> the </b> maximum <b> likelihood estimate, which is given by μ = (1/m) * ∑[yi * xi for i = 1 to m] </b>","<b> taking the derivative with </b> respect <b> to the parameters and setting it </b> equal <b> to zero, we can </b> solve <b> for the </b> expression <b> that </b> yields <b> the </b> maximum <b> likelihood estimate, which is given by μ = (1/m) * ∑[yi * xi for i = 1 to m] </b>"
An intuitive explanation around maximizes follows.,An intuitive explanation of how this maximises the likelihood follows.,An intuitive explanation <b> of how this maximises the likelihood </b> follows.,an intuitive explanation <b> of how this maximises the likelihood </b> follows.
"example, chance next office denoted bias coin toss fraction heads Likewise, just label y1.","For example, the chance of the next office being occupied is denoted by the bias of a coin toss, which is the fraction of heads. Likewise, we just label y as 1.","<b> For </b> example, <b> the </b> chance <b> of the </b> next office <b> being occupied is </b> denoted <b> by the </b> bias <b> of a </b> coin <b> toss, which is the </b> fraction <b> of heads. </b> Likewise, <b> we </b> just label <b> y as 1. </b>","<b> for </b> example, <b> the </b> chance <b> of the </b> next office <b> being occupied is </b> denoted <b> by the </b> bias <b> of a </b> coin <b> toss, which is the </b> fraction <b> of heads. </b> likewise, <b> we </b> just label <b> y as 1. </b>"
"way write indicator notation, mi11yi1m 1 argument true, otherwise 0.","We can write this in indicator notation as 1(yi = 1) = 1 if the argument is true, and 0 otherwise.","<b> We can </b> write <b> this in </b> indicator <b> notation as 1(yi = 1) = </b> 1 <b> if the </b> argument <b> is </b> true, <b> and 0 otherwise. </b>","<b> we can </b> write <b> this in </b> indicator <b> notation as 1(yi = 1) = </b> 1 <b> if the </b> argument <b> is </b> true, <b> and 0 otherwise. </b>"
true statement false equivalent ifstatement programming context.,This is equivalent to a true statement being false in an if-statement in a programming context.,<b> This is equivalent to a </b> true statement <b> being </b> false <b> in an if-statement in a </b> programming context.,<b> this is equivalent to a </b> true statement <b> being </b> false <b> in an if-statement in a </b> programming context.
"0,1 is, 0mi11yi0ximi11yi01mi11yi1","0 or 1 is given by 0 if yi = 0, and 1 if yi = 1.","<b> 0 or 1 is given by 0 if yi = 0, and 1 if yi = 1. </b>","<b> 0 or 1 is given by 0 if yi = 0, and 1 if yi = 1. </b>"
"intuition expression, think all say dataset.",The intuition behind this expression is to think about all the data points in the dataset.,<b> The </b> intuition <b> behind this expression is to </b> think <b> about </b> all <b> the data points in the </b> dataset.,<b> the </b> intuition <b> behind this expression is to </b> think <b> about </b> all <b> the data points in the </b> dataset.
"reasonable examples, 0s average writing intuition.",A reasonable example is to take the average of the 0s and 1s in the dataset.,<b> A </b> reasonable <b> example is to take the average of the </b> 0s <b> and 1s in the dataset. </b>,<b> a </b> reasonable <b> example is to take the average of the </b> 0s <b> and 1s in the dataset. </b>
"numerator sum feature sums entire summing i1m, uses instances yi0 times xi.","The numerator is the sum of the feature sums over the entire dataset, summing over all instances where yi = 0, and using the instances where yi = 1 times xi.","<b> The </b> numerator <b> is the </b> sum <b> of the </b> feature sums <b> over the </b> entire <b> dataset, </b> summing <b> over all </b> instances <b> where yi = 0, and using the instances where yi = 1 </b> times xi.","<b> the </b> numerator <b> is the </b> sum <b> of the </b> feature sums <b> over the </b> entire <b> dataset, </b> summing <b> over all </b> instances <b> where yi = 0, and using the instances where yi = 1 </b> times xi."
effect term whereas effectively zeroing term.,This has the effect of zeroing out the term.,<b> This has the </b> effect <b> of </b> zeroing <b> out the </b> term.,<b> this has the </b> effect <b> of </b> zeroing <b> out the </b> term.
up samples yi0.,This is because we are summing over all samples where yi = 0.,<b> This is because we are summing over all </b> samples <b> where yi = 0. </b>,<b> this is because we are summing over all </b> samples <b> where yi = 0. </b>
"count represent Because every yi0, get extra sum, ends total examples.","This is because every time yi = 0, we get an extra sum, which ends up being the total number of examples.","<b> This is because </b> every <b> time yi = 0, we </b> get <b> an </b> extra sum, <b> which </b> ends <b> up being the </b> total <b> number of </b> examples.","<b> this is because </b> every <b> time yi = 0, we </b> get <b> an </b> extra sum, <b> which </b> ends <b> up being the </b> total <b> number of </b> examples."
made 1mmi1xiyixiT fits means classes.,"This is made up of 1/m times the sum of xi times yi, which fits the means of the classes.","<b> This is </b> made <b> up of 1/m times the sum of xi times yi, which </b> fits <b> the </b> means <b> of the </b> classes.","<b> this is </b> made <b> up of 1/m times the sum of xi times yi, which </b> fits <b> the </b> means <b> of the </b> classes."
Making Predictions Using minz min z minimum any possible z.,"Making predictions using the minimum of z, where z is any possible value.","Making <b> predictions using the minimum of z, where </b> z <b> is </b> any possible <b> value. </b>","making <b> predictions using the minimum of z, where </b> z <b> is </b> any possible <b> value. </b>"
argminz argmin refers plugged expression.,The argmin of z refers to the value of z that minimises the expression.,<b> The </b> argmin <b> of z </b> refers <b> to the value of z that minimises the </b> expression.,<b> the </b> argmin <b> of z </b> refers <b> to the value of z that minimises the </b> expression.
"minzz52 attained z520 argminzz52 led z52, z5.","The minimum of z is attained when z = 5, and the argmin of z is 5.","<b> The minimum of z is </b> attained <b> when z = 5, and the argmin of z is 5. </b>","<b> the minimum of z is </b> attained <b> when z = 5, and the argmin of z is 5. </b>"
maxz argmaxz operators exist they deal leads having lets how go,"The max of z and the argmax of z are operators that exist, and they deal with the maximum value of z. Let's see how to go about finding the maximum value of z.","<b> The max of z and the argmax of z are </b> operators <b> that exist, and </b> they deal <b> with the maximum value of z. Let's see </b> how <b> to </b> go <b> about finding the maximum value of z. </b>","<b> the max of z and the argmax of z are </b> operators <b> that exist, and </b> they deal <b> with the maximum value of z. let's see </b> how <b> to </b> go <b> about finding the maximum value of z. </b>"
So do benign?,"So, do we predict benign?","<b> So, </b> do <b> we predict </b> benign?","<b> so, </b> do <b> we predict </b> benign?"
"boils down predicting likely x, formally argmaxyPyx","This boils down to predicting the most likely value of x, which is given by the argmax of Pyx.","<b> This </b> boils down <b> to </b> predicting <b> the most </b> likely <b> value of </b> x, <b> which is given by the argmax of Pyx. </b>","<b> this </b> boils down <b> to </b> predicting <b> the most </b> likely <b> value of </b> x, <b> which is given by the argmax of pyx. </b>"
"Looking deeper y0,1 rule, argmaxyPyxargmaxyPxyPyPx","Looking deeper, we can see that the rule for predicting y is given by the argmax of Pyx, which is equal to the argmax of PxyPyPx.","Looking <b> deeper, we can see that the rule for predicting y is given by the argmax of Pyx, which is equal to the argmax of PxyPyPx. </b>","looking <b> deeper, we can see that the rule for predicting y is given by the argmax of pyx, which is equal to the argmax of pxypypx. </b>"
reasons highlighted Visualization dataset compareandcontrast operate,"The reasons for this are highlighted in the visualisation of the dataset, which shows how the model operates.","<b> The </b> reasons <b> for this are </b> highlighted <b> in the visualisation of the dataset, which shows how the model operates. </b>","<b> the </b> reasons <b> for this are </b> highlighted <b> in the visualisation of the dataset, which shows how the model operates. </b>"
"Pictorially, GDAs operation Shown been shape orientation, share point, determine put together, imply blue Py1x0.5.","Pictorially, the operation of GDA is shown to be a shape and orientation that share a point, which determines the decision boundary. This implies that the blue line is the decision boundary, and Py1x = 0.5.","Pictorially, <b> the </b> operation <b> of GDA is shown to be a </b> shape <b> and orientation that </b> share <b> a </b> point, <b> which determines the decision boundary. This implies that the </b> blue <b> line is the decision boundary, and Py1x = 0.5. </b>","pictorially, <b> the </b> operation <b> of gda is shown to be a </b> shape <b> and orientation that </b> share <b> a </b> point, <b> which determines the decision boundary. this implies that the </b> blue <b> line is the decision boundary, and py1x = 0.5. </b>"
"boundary, predict outcome, side, y0.","The boundary is used to predict the outcome, and the side of the boundary determines the value of y.","<b> The boundary is used to </b> predict <b> the </b> outcome, <b> and the side of the boundary determines the value of y. </b>","<b> the boundary is used to </b> predict <b> the </b> outcome, <b> and the side of the boundary determines the value of y. </b>"
Points upper right closer classifying lower left classified,"Points in the upper right are closer to being classified as y = 1, while points in the lower left are classified as y = 0.","Points <b> in the </b> upper right <b> are </b> closer <b> to being classified as y = 1, while points in the </b> lower left <b> are </b> classified <b> as y = 0. </b>","points <b> in the </b> upper right <b> are </b> closer <b> to being classified as y = 1, while points in the </b> lower left <b> are </b> classified <b> as y = 0. </b>"
Logistic Regression x1 x2 start whose randomly.,"Logistic regression starts with x1 and x2, whose values are randomly initialised.","Logistic <b> regression starts with </b> x1 <b> and x2, </b> whose <b> values are randomly initialised. </b>","logistic <b> regression starts with </b> x1 <b> and x2, </b> whose <b> values are randomly initialised. </b>"
"Typically, initialize purpose visualization, starting off shown","Typically, we initialise the values for the purpose of visualisation, starting off with the values shown.","Typically, <b> we initialise the values for the </b> purpose <b> of visualisation, </b> starting off <b> with the values shown. </b>","typically, <b> we initialise the values for the </b> purpose <b> of visualisation, </b> starting off <b> with the values shown. </b>"
"Running single iteration PYX, repositions 20 iterations, converges illustrates green superimposed blue.","Running a single iteration of the algorithm, we reposition the decision boundary, and after 20 iterations, the algorithm converges, illustrating the green line superimposed on the blue line.","Running <b> a </b> single iteration <b> of the algorithm, we reposition the decision boundary, and after </b> 20 iterations, <b> the algorithm converges, illustrating the </b> green <b> line </b> superimposed <b> on the blue line. </b>","running <b> a </b> single iteration <b> of the algorithm, we reposition the decision boundary, and after </b> 20 iterations, <b> the algorithm converges, illustrating the </b> green <b> line </b> superimposed <b> on the blue line. </b>"
arrive slightly boundaries.,"We arrive at the decision boundary, which is slightly different from the original boundary.","<b> We </b> arrive <b> at the decision boundary, which is </b> slightly <b> different from the original boundary. </b>","<b> we </b> arrive <b> at the decision boundary, which is </b> slightly <b> different from the original boundary. </b>"
"Why Two Separate Means, Single Matrix?",Why do we have two separate means and a single matrix?,Why <b> do we have two separate means and a single matrix? </b>,why <b> do we have two separate means and a single matrix? </b>
If lot problems.,If we have a lot of problems.,If <b> we have a </b> lot <b> of </b> problems.,if <b> we have a </b> lot <b> of </b> problems.
"Choosing reasonable, work fine.",Choosing a reasonable value will work fine.,Choosing <b> a reasonable value will </b> work fine.,choosing <b> a reasonable value will </b> work fine.
"catch, though, youll roughly double isnt anymore.","The catch, though, is that you'll roughly double the number of parameters, and it isn't anymore.","<b> The </b> catch, though, <b> is that you'll </b> roughly double <b> the number of parameters, and it isn't </b> anymore.","<b> the </b> catch, though, <b> is that you'll </b> roughly double <b> the number of parameters, and it isn't </b> anymore."
Discussion Comparing interesting relationship.,The discussion compares the interesting relationship between,<b> The discussion compares the </b> interesting <b> relationship between </b>,<b> the discussion compares the </b> interesting <b> relationship between </b>
"youve ,0,1,.",You've seen the relationship between 0 and 1.,<b> You've seen the relationship between 0 and 1. </b>,<b> you've seen the relationship between 0 and 1. </b>
"fixed Py1x,0,1,.",The fixed value of Py1x is 0 or 1.,<b> The </b> fixed <b> value of Py1x is 0 or 1. </b>,<b> the </b> fixed <b> value of py1x is 0 or 1. </b>
"theorem, Pxy1,0,1,Pxy1,0,1,Py1Px,0,1,","By the theorem, Pxy1 = Pxy1,0,1,Py1Px,0,1,","<b> By the </b> theorem, <b> Pxy1 = Pxy1,0,1,Py1Px,0,1, </b>","<b> by the </b> theorem, <b> pxy1 = pxy1,0,1,py1px,0,1, </b>"
"where, Pxy1,0,1, measure evaluating once determined optimum probability, plot Py1x so, simple few","where Pxy1 is the measure of evaluating the optimum probability, and we plot Py1x, which is a simple function of a few variables.","<b> where Pxy1 is the </b> measure <b> of </b> evaluating <b> the </b> optimum probability, <b> and we </b> plot <b> Py1x, which is a </b> simple <b> function of a </b> few <b> variables. </b>","<b> where pxy1 is the </b> measure <b> of </b> evaluating <b> the </b> optimum probability, <b> and we </b> plot <b> py1x, which is a </b> simple <b> function of a </b> few <b> variables. </b>"
"Now, Mappingprojecting Xaxis, bump PXY0 PXY1.","Now, we map the X-axis to the bump of PXY0 and PXY1.","Now, <b> we map the X-axis to the </b> bump <b> of </b> PXY0 <b> and </b> PXY1.","now, <b> we map the x-axis to the </b> bump <b> of </b> pxy0 <b> and </b> pxy1."
"Were Also, note split 5050 across PY1 0.5, known half","We also note that the split is 50-50 across Py1 = 0.5, which is known as the half-way point.","<b> We also </b> note <b> that the </b> split <b> is 50-50 </b> across <b> Py1 = </b> 0.5, <b> which is </b> known <b> as the half-way point. </b>","<b> we also </b> note <b> that the </b> split <b> is 50-50 </b> across <b> py1 = </b> 0.5, <b> which is </b> known <b> as the half-way point. </b>"
"Next, PY1X X.","Next, we have Py1x = X.","Next, <b> we have Py1x = </b> X.","next, <b> we have py1x = </b> x."
unlabeled far Xaxis.,The unlabeled points are far away from the X-axis.,<b> The </b> unlabeled <b> points are </b> far <b> away from the X-axis. </b>,<b> the </b> unlabeled <b> points are </b> far <b> away from the x-axis. </b>
"infer point almost certainly came left, generating Xaxis datapoint very small.","We can infer that the point almost certainly came from the left, generating a datapoint very close to the X-axis.","<b> We can </b> infer <b> that the </b> point almost certainly came <b> from the </b> left, generating <b> a </b> datapoint very <b> close to the X-axis. </b>","<b> we can </b> infer <b> that the </b> point almost certainly came <b> from the </b> left, generating <b> a </b> datapoint very <b> close to the x-axis. </b>"
pick Its easy discern PXY10.5.,We can easily discern that PXY1 = 0.5.,<b> We can easily </b> discern <b> that PXY1 = 0.5. </b>,<b> we can easily </b> discern <b> that pxy1 = 0.5. </b>
"right, youd pretty sure class.","On the right, you'd be pretty sure of the class.","<b> On the </b> right, <b> you'd be </b> pretty sure <b> of the </b> class.","<b> on the </b> right, <b> you'd be </b> pretty sure <b> of the </b> class."
"repeat exercise sweeping datapoints dense grid evaluate measure, Youll notice coming approach midpoint, increases 0.5 surpasses 0.5.","If we repeat the exercise, sweeping the datapoints across a dense grid and evaluating the measure, you'll notice that as we approach the midpoint, the value increases to 0.5 and surpasses 0.5.","<b> If we </b> repeat <b> the exercise, </b> sweeping <b> the </b> datapoints <b> across a </b> dense grid <b> and evaluating the </b> measure, <b> you'll </b> notice <b> that as we </b> approach <b> the </b> midpoint, <b> the value </b> increases <b> to </b> 0.5 <b> and </b> surpasses 0.5.","<b> if we </b> repeat <b> the exercise, </b> sweeping <b> the </b> datapoints <b> across a </b> dense grid <b> and evaluating the </b> measure, <b> you'll </b> notice <b> that as we </b> approach <b> the </b> midpoint, <b> the value </b> increases <b> to </b> 0.5 <b> and </b> surpasses 0.5."
"Beyond certain tends Plotting connect dots, turns exactly view quantity Py1x,0,1,","Beyond a certain point, plotting the connect-the-dots turns exactly into the view of the quantity Py1x, which is 0 or 1.","Beyond <b> a </b> certain <b> point, plotting the connect-the-dots </b> turns exactly <b> into the </b> view <b> of the </b> quantity <b> Py1x, which is 0 or 1. </b>","beyond <b> a </b> certain <b> point, plotting the connect-the-dots </b> turns exactly <b> into the </b> view <b> of the </b> quantity <b> py1x, which is 0 or 1. </b>"
"find form, Py1x,,0,111expTx appropriate ,,0,1.","We find that the form of Py1x is given by the expression 1 / (1 + exp(-Tx)), which is appropriate for 0 or 1.","<b> We </b> find <b> that the form of Py1x is given by the expression 1 / (1 + exp(-Tx)), which is </b> appropriate <b> for 0 or 1. </b>","<b> we </b> find <b> that the form of py1x is given by the expression 1 / (1 + exp(-tx)), which is </b> appropriate <b> for 0 or 1. </b>"
"Py1x,,0,1.",Py1x is 0 or 1.,<b> Py1x is 0 or 1. </b>,<b> py1x is 0 or 1. </b>
convention redefining xis righthandside n1 dimensional adding coordinate xi01.,"By convention, we redefine the xis to be on the right-hand side, adding a coordinate xi0 = 1.","<b> By convention, we redefine the </b> xis <b> to be on the right-hand side, </b> adding <b> a </b> coordinate <b> xi0 = 1. </b>","<b> by convention, we redefine the </b> xis <b> to be on the right-hand side, </b> adding <b> a </b> coordinate <b> xi0 = 1. </b>"
1x.,This is 1 times x.,<b> This is 1 times x. </b>,<b> this is 1 times x. </b>
"While hypothesis function, hood specific choice choosing quite leading","While the hypothesis function is a specific choice, choosing it is quite leading.","While <b> the </b> hypothesis <b> function is a </b> specific <b> choice, </b> choosing <b> it is </b> quite <b> leading. </b>","while <b> the </b> hypothesis <b> function is a </b> specific <b> choice, </b> choosing <b> it is </b> quite <b> leading. </b>"
Would Prefer One Another?,Would you prefer one or the other?,Would <b> you prefer one or the other? </b>,would <b> you prefer one or the other? </b>
"general, yield boundaries trained","In general, the boundaries yielded by the trained models","<b> In </b> general, <b> the </b> boundaries <b> yielded by the </b> trained <b> models </b>","<b> in </b> general, <b> the </b> boundaries <b> yielded by the </b> trained <b> models </b>"
Which better?,Which one is better?,Which <b> one is </b> better?,which <b> one is </b> better?
discuss superior viceversa.,"We discuss which one is superior, and vice versa.","<b> We </b> discuss <b> which one is superior, and vice versa. </b>","<b> we </b> discuss <b> which one is superior, and vice versa. </b>"
"assumes that, xy0 xy1 parameter logistic, governed Py1x11expTx","It assumes that xy0 and xy1 are parameters of the logistic function, governed by Py1x = 1 / (1 + exp(-Tx)).","<b> It </b> assumes <b> that </b> xy0 <b> and </b> xy1 <b> are parameters of the logistic function, </b> governed <b> by Py1x = 1 / (1 + exp(-Tx)). </b>","<b> it </b> assumes <b> that </b> xy0 <b> and </b> xy1 <b> are parameters of the logistic function, </b> governed <b> by py1x = 1 / (1 + exp(-tx)). </b>"
"element x0, raised plotting pointbypoint ultimately yielded curve, shared necessarily assumptions","The element x0 is raised to the power of the plotting point-by-point, ultimately yielding a curve that shares the necessary assumptions.","<b> The </b> element <b> x0 is </b> raised <b> to the power of the </b> plotting <b> point-by-point, </b> ultimately <b> yielding a curve that shares the necessary assumptions. </b>","<b> the </b> element <b> x0 is </b> raised <b> to the power of the </b> plotting <b> point-by-point, </b> ultimately <b> yielding a curve that shares the necessary assumptions. </b>"
"3. converse, implication does Gaussian.","The converse is also true, and the implication is that the Gaussian distribution","<b> The converse is also true, and the </b> implication <b> is that the Gaussian distribution </b>","<b> the converse is also true, and the </b> implication <b> is that the gaussian distribution </b>"
"3 2. stronger prove 2, noted property GDA.","3 implies 2, and this is a stronger result. We prove 2, and note that this is a property of GDA.","3 <b> implies 2, and this is a </b> stronger <b> result. We </b> prove 2, <b> and note that this is a </b> property <b> of </b> GDA.","3 <b> implies 2, and this is a </b> stronger <b> result. we </b> prove 2, <b> and note that this is a </b> property <b> of </b> gda."
"correct, better regression.","This is correct, and better than regression.","<b> This is </b> correct, <b> and </b> better <b> than </b> regression.","<b> this is </b> correct, <b> and </b> better <b> than </b> regression."
"Specifically, indeed asymptotically efficient.","Specifically, it is indeed asymptotically efficient.","Specifically, <b> it is </b> indeed asymptotically efficient.","specifically, <b> it is </b> indeed asymptotically efficient."
"strong youre baking information algorithm, Informally, limit large sets m, there no strictly terms of, accurately","This is a strong result, and you're baking information into the algorithm. Informally, in the limit of large sets m, there is no strictly better algorithm in terms of accuracy.","<b> This is a </b> strong <b> result, and you're </b> baking information <b> into the algorithm. </b> Informally, <b> in the </b> limit <b> of </b> large sets m, there <b> is </b> no strictly <b> better algorithm in </b> terms <b> of accuracy. </b>","<b> this is a </b> strong <b> result, and you're </b> baking information <b> into the algorithm. </b> informally, <b> in the </b> limit <b> of </b> large sets m, there <b> is </b> no strictly <b> better algorithm in </b> terms <b> of accuracy. </b>"
